_target_: chimeralm.data.fq.DataModule

tokenizer:
  # _target_: chimera.data.tokenizer.CharacterTokenizer
  # model_max_length: 32768
  # padding_side: "right"

  _target_: chimeralm.data.tokenizer.load_tokenizer_from_hyena_model
  model_name: hyenadna-small-32k-seqlen

train_data_path: ${paths.root_dir}/data/train_data/p2_765108_bulk/train.parquet
val_data_path: ${paths.root_dir}/data/train_data/p2_765108_bulk/validation.parquet
test_data_path: ${paths.root_dir}/data/train_data/p2_765108_bulk/test.parquet
batch_size: 8 # Needs to be divisible by the number of devices (e.g., if in a distributed setup)
train_val_test_split: [0.7, 0.2, 0.1] # percent
num_workers: 0
pin_memory: False
