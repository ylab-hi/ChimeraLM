_target_: chimera.models.basic_module.ClassificationLit

net:
  _target_: chimera.models.transformer.SequenceCNNTransformer
  vocab_size: 12
  max_len: 32768
  d_model: 256
  cnn_kernel_size: 3
  dropout: 0.1
  num_encoder_layers: 12
  nhead: 8
  dim_feedforward: 1024

optimizer:
  _target_: torch.optim.AdamW
  _partial_: true
  lr: 0.0001
  weight_decay: 0.01

scheduler:
  _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  _partial_: true
  mode: min
  factor: 0.1
  patience: 6

criterion:
  _target_: torch.nn.CrossEntropyLoss

# compile model for faster training with pytorch 2.0
compile: false
